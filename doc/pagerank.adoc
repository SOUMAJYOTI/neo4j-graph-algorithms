= Page Rank

PageRank is Google's popular search algorithm. PageRank works by counting the number and quality of links to a page to determine a rough estimate of how important the website is. The underlying assumption is that more important websites are likely to receive more links from other websites

== History, Explanation



In order to measure the relative importance of web pages, Sergey Brin and Larry Page proposed PageRank, a method for
computing a ranking for every web page based on the graph of the web. PageRank has applications
in search, browsing, and traffic estimation.

PageRank is defined in the original Google paper as follows:

We assume page A has pages T1...Tn which point to it (i.e., are citations). The parameter d is a damping factor which can be set between 0 and 1. We usually set d to 0.85. Also C(A) is defined as the number of links going out of page A. The PageRank of a page A is given as follows:

PR(A) = (1-d) + d (PR(T1)/C(T1) + ... + PR(Tn)/C(Tn))

Note that the PageRanks form a probability distribution over web pages, so the sum of all web pages' PageRanks will be one.

The underlying mathematics of PageRank has to do with random walks on networks, akin to how random surfers propagate through a network. 
Precisely, PageRank is an example of a discrete ergodic Markov Chain. 
Random surfers follow links, but occasionally teleport to random vertices. 
The PageRank of a node is the probability it is visited by a random surfer with teleportation. 
PageRank is now widely recognized as a way of detecting central nodes in a network, and even has applications in systems biology.


== When to use it / use-cases

The mathematics of PageRank are entirely general and apply to any graph or network in any domain. 
Thus, PageRank is now regularly used in bibliometrics, social and information network analysis, and for link prediction and recommendation. 
It's even used for systems analysis of road networks, as well as biology, chemistry, neuroscience, and physics.

In neuroscience, the PageRank of a neuron in a neural network has been found to correlate with its relative firing rate.

Personalized PageRank is used by Twitter to present users with other accounts they may wish to follow.


PageRank has been used to rank spaces or streets to predict how many people (pedestrians or vehicles) come to the individual spaces or streets. In lexical semantics it has been used to perform Word Sense Disambiguation,Semantic similarity, and also to automatically rank WordNet synsets according to how strongly they possess a given semantic property, such as positivity or negativity.

In any ecosystem, a modified version of PageRank may be used to determine species that are essential to the continuing health of the environment.

For the analysis of protein networks in biology PageRank is also a useful tool.

Pagerank has recently been used to quantify the scientific impact of researchers. The underlying citation and collaboration networks are used in conjunction with pagerank algorithm in order to come up with a ranking system for individual publications which propagates to individual authors. The new index known as pagerank-index (Pi) is demonstrated to be fairer compared to h-index in the context of many drawbacks exhibited by h-index.

== Constraints / when not to use it


== Algorithm explanation on simple sample graph

image::{img}/pagerank.png[]

.Create sample graph
[source,cypher]
----
CREATE (home:Page{name:'Home'})
,(about:Page{name:'About'})
,(product:Page{name:'Product'})
,(links:Page{name:'Links'})
,(a:Page{name:'Site A'})
,(b:Page{name:'Site B'})
,(c:Page{name:'Site C'})
,(d:Page{name:'Site D'})
CREATE (home)-[:LINKS]->(about)
,(about)-[:LINKS]->(home)
,(product)-[:LINKS]->(home)
,(home)-[:LINKS]->(product)
,(links)-[:LINKS]->(home)
,(home)-[:LINKS]->(links)
,(links)-[:LINKS]->(a)-[:LINKS]->(home)
,(links)-[:LINKS]->(b)-[:LINKS]->(home)
,(links)-[:LINKS]->(c)-[:LINKS]->(home)
,(links)-[:LINKS]->(d)-[:LINKS]->(home)

----


.Running algorithm and streaming results
[source,cypher]
----

CALL algo.pageRank.stream('Page', 'LINKS', {iterations:20, dampingFactor:0.85}) 
YIELD node, score 
RETURN node,score order by score desc limit 20

----


.Running algorithm and writing back results 
[source,cypher]
----

CALL algo.pageRank('Page', 'LINKS', {iterations:20, dampingFactor:0.85, 
write: true,writeProperty:"pagerank"}) 
YIELD nodes, iterations, loadMillis, computeMillis, writeMillis, dampingFactor, write, writeProperty 

----


.Results
[opts="header",cols="1,1"]
|===
| name | pageRank 
| Home | 3.232
| Product | 1.059
| Links | 1.059
| About | 1.059
| Site A | 0.328
| Site B | 0.328 
| Site C | 0.328 
| Site D | 0.328 
|===

As we expected, we see that Home page has the highest pageRank, because it has incoming links from all other pages. We can also observe, that not only the number of incoming links is important, but also the importance of the page, that links to us. 

== Example Usage

.minimal
[source,cypher]
----
CALL algo.pageRank('Label1', 'TYPE1') YIELD computeMillis
CALL algo.pageRank.stream('Label1', 'TYPE1') YIELD node, score order by score desc limit 20
----

== Syntax

.running algorithm and writing back results
[source,cypher]
----
CALL algo.pageRank(label:String, relationship:String, {iterations:20, dampingFactor:0.85, 
write: true,writeProperty:'pagerank', concurrency:8}) 
YIELD nodes, iterations, loadMillis, computeMillis, writeMillis, dampingFactor, write, writeProperty 
- calculates page rank and potentially writes back
----

.parameters
[opts="header",cols="1,1,1,1,4"]
|===
| name | type | default | optional | description
| label  | string | null | yes | label to load from the graph, if null load all nodes
| relationship | string | null | yes | relationship-type to load from the graph, if null load all nodes
| iterations | int | 20 | yes | how many iterations of page-rank to run
| concurrency | int | available CPUs | yes | number of concurrent threads
| dampingFactor | float | 0.85 | yes | damping factor of the page-rank calculation
| write | boolean | true | yes | if result should be written back as node property
| writeProperty | string | 'pagerank' | yes | property name written back to
| graph | string | 'heavy' | yes | use 'heavy' when describing the subset of the graph with label and relationship-type parameter, 'cypher' for describing the subset with cypher node-statement and relationship-statement
|===

.results
[opts="header",cols="1,1,6"]
|===
| name | type | description
| nodes | int | number of nodes considered
| iterations | int | number of iterations run
| dampingFactor | float | damping factor used
| writeProperty | string | property name written back to
| write | boolean | if result was written back as node property
| loadMillis | int | milliseconds for loading data
| computeMillis | int | milliseconds for running the algorithm
| writeMillis | int | milliseconds for writing result data back

|===


.running algorithm and streaming results
[source,cypher]
----
CALL algo.pageRank.stream(label:String, relationship:String, 
{iterations:20, dampingFactor:0.85, concurrency:8})
YIELD node, score - calculates page rank and streams results
----

.parameters
[opts="header",cols="1,1,1,1,4"]
|===
| name | type | default | optional | description
| label  | string | null | yes | label to load from the graph, if null load all nodes
| relationship | string | null | yes | relationship-type to load from the graph, if null load all nodes
| iterations | int | 20 | yes | how many iterations of page-rank to run
| concurrency | int | available CPUs | yes | number of concurrent threads
| dampingFactor | float | 0.85 | yes | damping factor of the page-rank calculation
|===

.results
[opts="headers"]
|===
| name | type | description
| node | long | node id
| score | float | page-rank weight 
|===


== Cypher loading

If label and relationship-type are not selective enough to describe your subgraph to run the algorithm on, you can use Cypher statements to load or project subsets of your graph.
Can be also used to run algorithms on a virtual graph.
Set `graph:'cypher'` in the config.

[source,cypher]
----
CALL algo.pageRank(
'MATCH (p:Page) RETURN id(p) as id',
'MATCH (p1:Page)-[:Link]->(p2:Page) RETURN id(p1) as source, id(p2) as target',
{graph:'cypher', iterations:5, write: true});
----

== Versions 

We support the following versions of the pageRank algorithm:

* [x] directed, unweighted

* [ ] directed, weighted

* [ ] undirected, unweighted

* [ ] undirected, weighted 

== References

* https://en.wikipedia.org/wiki/PageRank

* http://infolab.stanford.edu/~ullman/mmds/book.pdf

* http://ilpubs.stanford.edu:8090/422/1/1999-66.pdf

* http://www.cs.princeton.edu/~chazelle/courses/BIB/pagerank.htm

* https://anthonybonato.com/2016/04/13/the-mathematics-of-game-of-thrones/

ifdef::implementation[]
// tag::implementation[]

== Implementation Details

// copied from: https://github.com/neo4j-contrib/neo4j-graph-algorithms/issues/78

:leveloffset: +1

_PageRank_ is Googles popular search algorithm.

More: https://en.wikipedia.org/wiki/PageRank

## Progress

- [x] single threaded implementation
- [x] tests
- [x] simple benchmark
- [x] implement procedure
- [x] benchmark on bigger graphs
- [x] parallelization
- [x] evaluation

## Requirements

- NodeIterator
- Incoming Relationships
- Outgoing Degrees

## Data structured involved

Our current approach needs one double array for storing ranks.

## ToDo

### parallelization

One approach to parallelize _PageRank_ might be to partition the node into batches - one for each thread. Nonetheless we may need to sync them at the end of each iteration.

### evaluation

- Performance tests on different dataset sizes / level of concurrency

## Future Improvements

- we might scale up the ranks to ints for faster multiplication.

== Details

Partition based parallel PageRank based on "An Efficient Partition-Based Parallel PageRank Algorithm" [1]-

- Each partition thread has its local array of only the nodes that it is responsible for,
not for all nodes. Combined, all partitions hold all page rank scores for every node once.
Instead of writing partition files and transferring them across the network
(as done in the paper since they were concerned with parallelising across multiple nodes),
we use integer arrays to write the results to.
The actual score is upscaled from a double to an integer by multiplying it with {@code 100_000}.

- To avoid contention by writing to a shared array, we partition the result array.
- During execution, the scores arrays are shaped like this:

    [ executing partition ] -> [ calculated partition ] -> [ local page rank scores ]

- Each single partition writes in a partitioned array, calculation the scores
 for every receiving partition. A single partition only sees:

    [ calculated partition ] -> [ local page rank scores ]

- The coordinating thread then builds the transpose of all written partitions from every partition:

    [ calculated partition ] -> [ executing partition ] -> [ local page rank scores ]

- This step does not happen in parallel, but does not involve extensive copying.
The local page rank scores needn't be copied, only the partitioning arrays.
All in all, {@code concurrency^2} array element reads and assignments have to
be performed.

- For the next iteration, every partition first updates its scores, in parallel.
A single partition now sees:

    [ executing partition ] -> [ local page rank scores ]

- That is, a list of all calculated scores for it self, grouped by the partition that
calculated these scores.
This means, most of the synchronization happens in parallel, too.

- Partitioning is not done by number of nodes but by the accumulated degree –
as described in "Fast Parallel PageRank: A Linear System Approach" [2].
Every partition should have about the same number of relationships to operate on.
- This is done to avoid having one partition with super nodes and instead have
all partitions run in approximately equal time.
Smaller partitions are merged down until we have at most {@code concurrency} partitions,
in order to batch partitions and keep the number of threads in use predictable/configurable.

[1]: An Efficient Partition-Based Parallel PageRank Algorithm
[2]: <a href="https://www.cs.purdue.edu/homes/dgleich/

// end::implementation[]
endif::implementation[]
